# Suppose in the A/B testing system, there is an ability to track 100 metrics, each of which has the following characteristics:

# For a 10% sample - metric value from 90 to 110 (normal distribution with a mean of 100 and variance of 10)

# For a 90% sample - 0

# This behavior is similar to, for example, conversion to the purchase of subscription services. Let's conduct an A/B test with two identical groups (AA test) and compare pairwise all metrics using a t-test.


import numpy as np
import pandas as pd
import scipy.stats as st


def generate_data(n_users: int = 10 ** 5, n_metrics: int = 100) -> pd.DataFrame:
    user_ids = np.arange(n_users)
    data = pd.DataFrame(user_ids, columns=["user_id"])
    for metric_number in range(n_metrics):
        data = pd.concat(
            [
                data,
                pd.DataFrame(
                    np.random.normal(100, 10, size=n_users)
                    * np.random.choice([0, 1], size=n_users, p=[0.9, 0.1]),
                    columns=[f"metric_{metric_number}"],
                    index=data.index,
                ),
            ],
            axis=1,
        )
    data = data.set_index("user_id")
    return data


data_a = generate_data()
data_b = generate_data()

significance = []

for column in data_a.columns[1:]:
    p_value = st.ttest_ind(data_a[column], data_b[column])[1]
    if p_value < 0.05:
        significance.append(1)
    else:
        significance.append(0)

metric_names = data_a.columns[1:]
result_df = pd.DataFrame({"Metric": metric_names, "Significant": significance})

significant_metrics = result_df[result_df["Significant"] == 1]

print(significant_metrics)
